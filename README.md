# Nutrition RAG Chatbot: Built from Scratch

A fully manual **Retrieval-Augmented Generation (RAG)** system built without any frameworks like LangChain or LangGraph. This chatbot answers nutrition-related questions grounded strictly in:

**Human Nutrition Textbook** (University of Hawai'i at MÄnoa)  
ğŸ“„ [PDF Source]([https://pressbooks.oer.hawaii.edu/humannutrition2/open/download?type=pdf](https://pressbooks.oer.hawaii.edu/humannutrition2/))

---

## ğŸ¯ Project Highlights

- âœ… **No RAG frameworks** â€“ Everything engineered from scratch
- âœ… **Custom chunking strategies** â€“ Sentence-based with overlap
- âœ… **Local embeddings** â€“ Using `nomic-embed-text-v1.5` via Sentence Transformers
- âœ… **PostgreSQL + pgvector** â€“ No external vector databases
- âœ… **Streaming responses** â€“ Real-time generation with inline citations
- âœ… **Full-stack implementation** â€“ Next.js frontend + API backend

---

## ğŸ“¸ Interface
<img width="1200" height="600" alt="image" src="https://github.com/user-attachments/assets/63e7aa67-e856-4333-b6ba-97665b147cc3" />
<img width="1200" height="600" alt="image" src="https://github.com/user-attachments/assets/16bce67b-efdf-4b1c-8306-662f98066b31" />

---

## ğŸ—ï¸ System Architecture

```
PDF Document
    â†“
Text Extraction (PyMuPDF)
    â†“
Custom Sentence-based Chunking
    â†“
Local Embedding Generation (nomic-embed-text-v1.5)
    â†“
PostgreSQL + pgvector Storage
    â†“
Cosine Similarity Search
    â†“
LLM Response Generation (Groq)
```

---

## ğŸ”§ Core Components

### **1. Document Ingestion** (`ingest.py`)
- Extracts text from PDF using PyMuPDF
- Implements custom **sentence-based chunking**:
  - 20 sentences per chunk
  - 2-sentence overlap between chunks
  - Token safety cap at 1300 tokens
  - Minimum 50 tokens per chunk
- Generates embeddings locally using Sentence Transformers
- Stores everything in PostgreSQL with pgvector

### **2. Backend API** (`route.ts`)
- Self-hosted embedding endpoint integration
- Vector similarity search via SQL
- Streaming LLM responses with **inline citations**
- Wikipedia-style reference formatting
- Dynamic response formatting (paragraphs vs bullet points)

---

## ğŸ“Š Database Architecture

**PostgreSQL with pgvector extension** stores:
- Document chunks with content
- 768-dimensional embedding vectors
- Page metadata for citations
- IVFFlat index for fast cosine similarity search

Custom SQL function enables efficient similarity matching with optional metadata filtering.

---

## ğŸš€ Setup Instructions

### **Prerequisites**
- Python 3.8+
- PostgreSQL with pgvector extension
- Node.js 18+

### **Installation Steps**

**1. Clone Repository**
```bash
git clone https://github.com/Pariskarpoudel/Nutritional_RAG_From_Scratch
cd Nutritional_RAG_From_Scratch
```

**2. Python Environment Setup**
```bash
python3 -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate
pip install pymupdf tiktoken supabase sentence-transformers tqdm python-dotenv
```

**3. Configure Environment Variables**

Create `.env` file with:
- Supabase URL and service role key
- Hugging Face embedding API endpoint

**4. Run Document Ingestion**
```bash
python ingest.py
```

**5. Frontend Setup**
```bash
cd rag-chat
npm install
```

Create `.env.local` with database credentials and API keys.

**6. Launch Application**
```bash
npm run dev
```

Access at: `http://localhost:3000`

---

## ğŸ“ Repository Structure

```
.
â”œâ”€â”€ ingest.py                    # Document ingestion & chunking
â”œâ”€â”€ human-nutrition-text.pdf     # Source document
â”œâ”€â”€ rag-chat/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â””â”€â”€ app/
â”‚   â”‚       â”œâ”€â”€ api/
â”‚   â”‚       â”‚   â””â”€â”€ chat/
â”‚   â”‚       â”‚       â””â”€â”€ route.ts  # Backend API
â”‚   â”‚       â””â”€â”€ page.tsx          # Frontend UI
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ .env                          # Environment variables
â””â”€â”€ README.md
```

---

## ğŸ¨ Key Features

### **Custom Chunking Strategy**
- Sentence-based approach with configurable overlap
- Handles hyphenation and whitespace normalization
- Token-aware chunking with safety caps
- Preserves page metadata for accurate citations

### **Citation System**
- Inline citations with [1], [2] format
- Page numbers displayed for each source
- Similarity scores shown for transparency
- Full source context available on hover

---

## ğŸ§  How It Works

**Query Processing Pipeline:**

1. **User Query** â†’ Converted to embedding vector using local model
2. **Vector Search** â†’ Top 8 most similar chunks retrieved from database
3. **Context Assembly** â†’ Chunks formatted with numbered citations
4. **LLM Generation** â†’ Groq streams grounded response in real-time
5. **Frontend Display** â†’ Response rendered with interactive citations

The system ensures every factual claim is backed by source material, preventing hallucinations and maintaining accuracy.

---

## ğŸ”® Future Improvements

- [ ] Implement re-ranking for retrieved chunks
- [ ] Add multi-vector scoring per chunk
- [ ] Enhanced citation UI with expandable sources
- [ ] Support for multiple nutrition documents
- [ ] Docker containerization for easy deployment
- [ ] Evaluation metrics dashboard

---

## ğŸ“„ License

MIT License - See [LICENSE](LICENSE) for details

---

## ğŸ‘¤ Author

**Pariskar Sharma Poudel**  
GitHub: [https://github.com/Pariskarpoudel/]  
Project: [[Repository Link](https://github.com/Pariskarpoudel/Nutritional_RAG_From_Scratch)]

---
